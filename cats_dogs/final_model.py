import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os

# =========================
# ПАРАМЕТРЫ
# =========================
BATCH_SIZE = 32      # Размер пакета (batch). Определяет, сколько изображений 
                     # обрабатывается за один шаг при обучении.
IMG_HEIGHT = 180     # Высота входного изображения (после изменения размера).
IMG_WIDTH = 180      # Ширина входного изображения (после изменения размера).
EPOCHS = 10          # Количество эпох. 1 эпоха = полный проход по всему датасету.

# =========================
# ПУТЬ К ДИРЕКТОРИИ С ДАННЫМИ
# =========================
# Предполагается, что в папке 'train' лежат подпапки с названиями классов:
# например, 'cats' и 'dogs'. Файлы изображений внутри каждой подпапки.
data_dir = r"C:\Users\Asus\Documents\python_cookies\alpha\cats_dogs\cats_and_dogs_filtered\train"

# =========================
# ЗАГРУЗКА ДАТАСЕТА
# =========================
# Используем image_dataset_from_directory для автоматического считывания
# изображений, их изменения размеров (image_size) и формирования батчей (batch_size).
# Параметр validation_split=0.2 означает, что 20% данных мы отложим на валидацию.
# subset указывает, какой именно кусок берем: 'training' или 'validation'.
train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,        # Берём 80% на обучение, 20% на валидацию
    subset="training",           # Этот датасет - обучающая выборка
    seed=123,                    # Фиксируем seed для воспроизводимости разбиения
    image_size=(IMG_HEIGHT, IMG_WIDTH),  # Приведение всех изображений к (180x180)
    batch_size=BATCH_SIZE        # Размер пакета
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",         # Этот датасет - валидационная выборка
    seed=123,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE
)

# =========================
# ПОДГОТОВКА ДАТЫ (Prefetch)
# =========================
# Prefetch (предвыборка) позволяет загружать и обрабатывать следующий батч
# в фоновом режиме, пока модель обучается на текущем батче, ускоряя процесс.
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# =========================
# СЛОЙ НОРМАЛИЗАЦИИ (RESCALING)
# =========================
# Rescaling(1./255) преобразует значения пикселей из диапазона [0..255] 
# в диапазон [0..1], что помогает более стабильному обучению.
normalization_layer = tf.keras.layers.Rescaling(1. / 255)

# =========================
# СОЗДАНИЕ МОДЕЛИ (СВЁРТОЧНАЯ НЕЙРОННАЯ СЕТЬ, CNN)
# =========================
model = tf.keras.Sequential([
    # ------------------------------------------
    # 1) ЛУЧШЕ СНАЧАЛА УПОМЯНУТЬ НОРМАЛИЗАЦИЮ
    # ------------------------------------------
    # Вы можете вставить normalization_layer в начало,
    # чтобы все входные пиксели сразу приводить к [0..1].
    normalization_layer,

    # ------------------------------------------
    # 2) CONV2D (32 ФИЛЬТРА), ЯДРО 3x3
    # ------------------------------------------
    # Conv2D — это сверточный слой, который "сканирует" изображение с помощью
    # набора фильтров, выделяя признаки (edges, текстуры и т.д.).
    # - 32: количество фильтров (число разных детектируемых признаков)
    # - (3,3): размер каждого фильтра (по высоте и ширине)
    # - activation='relu': функция активации ReLU, которая отбрасывает 
    #   отрицательные значения, ускоряя обучение и уменьшая переобучение.
    # - input_shape: ожидаемый размер входа — (180, 180, 3)
    #   (3 канала для RGB-изображений).
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),

    # ------------------------------------------
    # 3) MAXPOOLING2D
    # ------------------------------------------
    # MaxPooling2D снижает разрешение карты признаков, беря максимальное
    # значение в окне (2x2) и тем самым уменьшая количество параметров.
    # Это помогает модели обобщать и сокращает вычислительные затраты.
    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),

    # ------------------------------------------
    # 4) ЕЩЁ ОДИН СВЁРТОЧНЫЙ СЛОЙ (64 ФИЛЬТРА)
    # ------------------------------------------
    # В увеличении количества фильтров (32 -> 64) модель может
    # обучиться большему количеству, более сложных признаков.
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),

    # Повторяем MaxPooling2D для сжатия карты признаков.
    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),

    # ------------------------------------------
    # 5) ТРЕТИЙ СВЁРТОЧНЫЙ СЛОЙ (128 ФИЛЬТРОВ)
    # ------------------------------------------
    # Продолжаем увеличивать глубину сети (64 -> 128), чтобы
    # охватить ещё более сложные паттерны.
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),

    # ------------------------------------------
    # 6) FLATTEN
    # ------------------------------------------
    # Преобразуем выход 3D-тензора из свёрточных слоёв в 1D-вектор,
    # чтобы затем передать в полносвязные слои.
    tf.keras.layers.Flatten(),

    # ------------------------------------------
    # 7) ПОЛНОСВЯЗНЫЙ СЛОЙ (Dense)
    # ------------------------------------------
    # 128 нейронов — это произвольный выбор; чем больше нейронов,
    # тем сильнее модель, но и выше риск переобучения.
    tf.keras.layers.Dense(128, activation='relu'),

    # ------------------------------------------
    # 8) DROPOUT
    # ------------------------------------------
    # Dropout(rate=0.5) означает, что мы "выключаем" 50% нейронов
    # случайным образом во время обучения, чтобы модель не переучивалась
    # на конкретные признаки.
    tf.keras.layers.Dropout(0.5),

    # ------------------------------------------
    # 9) ВЫХОДНОЙ СЛОЙ (1 НЕЙРОН С SIGMOID)
    # ------------------------------------------
    # Для бинарной классификации (кошка/собака) достаточно одного выхода.
    # Если output < 0.5, мы можем интерпретировать как класс 0 (кошка),
    # иначе класс 1 (собака).
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# =========================
# КОМПИЛЯЦИЯ МОДЕЛИ
# =========================
# - optimizer='adam': адаптивный метод оптимизации, часто хороший дефолт.
# - loss='binary_crossentropy': функция потерь при бинарной классификации.
# - metrics=['accuracy']: метрика точности, удобна для отслеживания.
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# =========================
# ОБУЧЕНИЕ МОДЕЛИ
# =========================
# - train_ds: обучающий датасет
# - validation_data=val_ds: валидационный датасет
# - epochs=EPOCHS: количество проходов по всему датасету.
print("Начинаем обучение...")
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS
)

# =========================
# ТЕСТИРОВАНИЕ НА РЕАЛЬНОМ ИЗОБРАЖЕНИИ
# =========================
# 1) Загружаем изображение и приводим к нужному размеру (180x180)
# 2) Преобразуем в numpy-массив
# 3) Формируем батч из 1 изображения (expand_dims)
# 4) Предсказываем
# 5) Если результат < 0.5 => 'Кошка', иначе => 'Собака'.

test_image_path = "cat1.jpg"  # Замените на путь к вашему тестовому изображению

img = tf.keras.utils.load_img(test_image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
img = tf.keras.utils.img_to_array(img)
img = np.expand_dims(img, axis=0)

prediction = model.predict(img)

class_label = "Кошка" if prediction[0] < 0.5 else "Собака"
print(f"Класс изображения: {class_label}")
